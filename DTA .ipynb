{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "vi74SZgBc47M"
      },
      "outputs": [],
      "source": [
        "traning_data =[\n",
        "    ['Green',3,'Mango'],\n",
        "    ['Yellow',3,'Mango'],\n",
        "    ['Red',1,'Grape'],\n",
        "    ['Red',1,'Grape'],\n",
        "    ['Yellow',3,'Lemon'],\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traning_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cv80n6MeMOA",
        "outputId": "98d02c4d-5694-4d21-ecc9-bce6b8023dee"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Green', 3, 'Mango'],\n",
              " ['Yellow', 3, 'Mango'],\n",
              " ['Red', 1, 'Grape'],\n",
              " ['Red', 1, 'Grape'],\n",
              " ['Yellow', 3, 'Lemon']]"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "header = [\"color\",\"diameter\",\"label\"]"
      ],
      "metadata": {
        "id": "66M5sCy5eRU1"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unique_vals(rows,col):\n",
        "  # unique values\n",
        "  return set([row[col] for row in rows])\n",
        "\n",
        "# unique_vals(traning_data,1)"
      ],
      "metadata": {
        "id": "oUaxM-19eaxa"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def class_counts(rows):\n",
        "  # Counts the number of each type pf example in dataset\n",
        "  counts = {}\n",
        "  for row in rows:\n",
        "    label = row[-1]\n",
        "    if label not in counts:\n",
        "        counts[label]=0\n",
        "    counts[label] +=1\n",
        "  return counts"
      ],
      "metadata": {
        "id": "DqOOdVt4f7w-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_numeric(value):\n",
        "  # Test if a avlue is Numric\n",
        "  return isinstance(value,int) or isinstance(value,float)"
      ],
      "metadata": {
        "id": "9zIBaHCqhLQm"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Question:\n",
        "    # A Question is used to partition a dataset.\n",
        "    # This class just records a 'column number' (e.g. 0 for color) and a\n",
        "    # 'column value' (e.g Green). This 'match' method is used to compare\n",
        "    # the feature value in an example to the feature value stored in\n",
        "    # the question. See the demo below.\n",
        "    def __init__(self, column, value):\n",
        "        self.column = column\n",
        "        self.value = value\n",
        "    def match(self,example):\n",
        "      # Compare the Feature value in an example\n",
        "      # feature value in this question\n",
        "      val = example[self.column]\n",
        "      if is_numeric(val):\n",
        "        return val >= self.value\n",
        "      else:\n",
        "        return val == self.value\n",
        "    def __repr__(self):\n",
        "      #This is just a helper method to print\n",
        "      #the questation in a readable formate\n",
        "      condition=\"==\"\n",
        "      if is_numeric(self.value):\n",
        "        condition = \">=\"\n",
        "      return \"Is %s %s %s?\" %(\n",
        "          header[self.column],condition,str(self.value)\n",
        "      )\n",
        "\n"
      ],
      "metadata": {
        "id": "nO9O-w19iOel"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def partition(rows,question):\n",
        "  ture_rows,false_rows=[],[]\n",
        "  for row in rows:\n",
        "    if question.match(row):\n",
        "        ture_rows.append(row)\n",
        "    else:\n",
        "         false_rows.append(row)\n",
        "  return ture_rows,false_rows\n",
        "     #Partitions a dataset.\n",
        "     #For each row in the dataset, check if it matches the question. If so, add it to 'true rows, otherwise, add it to 'false rows\".\n"
      ],
      "metadata": {
        "id": "Yag0Hs-V2B8P"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Demo:\n",
        "# Let's partition the training data based on whether rows are Red. I\n",
        "#true rows, false rows = partition(training data, Question(e, 'Red'))\n",
        "#This will contain all the 'Red' rows.\n",
        "# true_rows\n",
        "# This will contain everything else.\n",
        "#false_rows"
      ],
      "metadata": {
        "id": "vXiHJMjhE2l8"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"\"Calculate the Gini Impurity for a list of rows. There are a few different ways to do this, I thought this one was the most concise. See: https://en.wikipedia.org/wiki/Decision tree learning#Gini_impurity"
      ],
      "metadata": {
        "id": "E9BS2iMHFkAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gini(rows):\n",
        "  counts = class_counts(rows)\n",
        "  impurity=1\n",
        "  for lbl in counts:\n",
        "      prob_of_lbl = counts[lbl]/float(len(rows))\n",
        "      impurity -= prob_of_lbl**2\n",
        "  return impurity"
      ],
      "metadata": {
        "id": "BVG8zCX0Fms5"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Information Gain. I The uncertainty of the starting node, minus the weighted impurity of two child nodes."
      ],
      "metadata": {
        "id": "SfA-znkuGUvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Demo:\n",
        "Calculate the uncertainy of our training data. current uncertainty gini(training data)\n",
        "\n",
        "How much information do we gain by partioning on 'Green'?\n",
        "true rows, false rows = partition(training data, Question(e, Green')) info gain(true rows, false rows, current uncertainty)\n",
        "What about if we partioned on 'Red' instead?\n",
        "true rows, false rows = partition(training data, Question (0, 'Red'))  info_gain(true rows, false rows, current_uncertainty)"
      ],
      "metadata": {
        "id": "dbZ6B5AaRDMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def info_gain(left,right,current_uncertanity):\n",
        "    p=float(len(left))/(len(left)+len(right))\n",
        "    return current_uncertanity - p * gini(left)-(1-p)*gini(right)"
      ],
      "metadata": {
        "id": "DatW2jraGVOQ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find the best question to ask by iterating over every feature / value and calculating the information gain"
      ],
      "metadata": {
        "id": "cvpXeyXhReC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(rows):\n",
        "    best_gain = 0\n",
        "    best_question = None\n",
        "    current_uncertainty = gini(rows)\n",
        "    n_features = len(rows[0]) - 1\n",
        "\n",
        "    for col in range(n_features):\n",
        "        values = set([row[col] for row in rows])\n",
        "\n",
        "        for val in values:\n",
        "            question = Question(col, val)\n",
        "            true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "            if len(true_rows) == 0 or len(false_rows) == 0:\n",
        "                continue\n",
        "\n",
        "            gain = info_gain(true_rows, false_rows, current_uncertainty)\n",
        "\n",
        "            if gain >= best_gain:\n",
        "                best_gain, best_question = gain, question\n",
        "\n",
        "    return best_gain, best_question"
      ],
      "metadata": {
        "id": "dnTqligDQ4pT"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Leaf:\n",
        "  #\"A Leaf node classifies data.\n",
        "  #This holds a dictionary of class (e.g., \"Mango\") -> number of times\n",
        "  #it appears in the rows from the training data that reach this leaf.\n",
        "  def __init__(self,rows):\n",
        "    self.predictions=class_counts(rows)\n",
        "class Decision_Node:\n",
        "  #A Decision Node asks a question.\n",
        "  #This holds a reference to the question, and to the two child nodes.\n",
        "  def __init__(self,question,true_branch,flase_branch):\n",
        "    self.question=question\n",
        "    self.true_branch=true_branch\n",
        "    self.flase_branch =flase_branch\n"
      ],
      "metadata": {
        "id": "CI_IGEwQTjmj"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Builds the tree\n",
        "Try partitioing the dataset on each of the unique attribute calculate the information gain and return the question that produces the highest gain."
      ],
      "metadata": {
        "id": "QWWEaHWgUvpd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def build_tree(rows):\n",
        "    # Try partitioning the dataset on each of the unique attributes,\n",
        "    # calculate the information gain, and return the question that produces the highest gain.\n",
        "    gain, question = find_best_split(rows)\n",
        "\n",
        "    # Base case: no further info gain.\n",
        "    # Since we can ask no further questions, we'll return a Leaf.\n",
        "    if gain == 0:\n",
        "        return Leaf(rows)\n",
        "\n",
        "    # If we reach here, we have found a useful feature / value to partition on.\n",
        "    true_rows, false_rows = partition(rows, question)\n",
        "\n",
        "    # Recursively build the true branch.\n",
        "    true_branch = build_tree(true_rows)\n",
        "\n",
        "    # Recursively build the false branch.\n",
        "    false_branch = build_tree(false_rows)\n",
        "\n",
        "    # Return a Decision_Node.\n",
        "    # This records the best feature / value to ask at this point,\n",
        "    # as well as the branches to follow depending on the answer.\n",
        "    return Decision_Node(question, true_branch, false_branch)"
      ],
      "metadata": {
        "id": "DS8L8mgpWh47"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tree(node , spacing=\"\"):\n",
        "  # World's most elegant tree printing funtion\n",
        "    if isinstance(node,Leaf):\n",
        "         print(spacing+\"Predict\",node.predictions)\n",
        "         return\n",
        "\n",
        "    print(spacing+str(node.question))\n",
        "  #call this function recursively on the true branch print (spacing+ --> True:')\n",
        "    print(spacing+'---> True')\n",
        "    print_tree(node.true_branch,spacing+\" \")\n",
        "  #call this function recursively on the false branch print (spacing+ --> False:') print tree(node.false branch, spacing + \" \" \")\n",
        "    print(spacing +'--> False')\n",
        "    print_tree(node.flase_branch,spacing+\" \")"
      ],
      "metadata": {
        "id": "DWjefBkLan5I"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(row,node):\n",
        "  # Base case : we've reached a leaf\n",
        "  if isinstance(node,Leaf):\n",
        "    return node.predictions\n",
        "  # Decide Wheather to follow the true-branch or the false-branch\n",
        "  # Compare the feayure / value stored in the node,\n",
        "  # tp the example we're considering\n",
        "  if node.question.match(row):\n",
        "    return classify(row,node.true_branch)\n",
        "  else:\n",
        "    return classify(row,node.flase_branch)"
      ],
      "metadata": {
        "id": "YQ4IB7yZkb9P"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_leaf(counts):\n",
        "# print the predictions at a leaf\n",
        "  total = sum(counts.values())*1.0\n",
        "  probs={}\n",
        "  for lbl in counts.keys():\n",
        "    probs[lbl]=str(int(counts[lbl]/total*100))+\"%\"\n",
        "  return probs"
      ],
      "metadata": {
        "id": "nRGMYPyAlTpG"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    my_tree = build_tree(traning_data)\n",
        "    print_tree(my_tree)\n",
        "    testing_data = [\n",
        "        ['Green', 3, 'Mango'],\n",
        "        ['Yellow', 4, 'Mango'],\n",
        "        ['Red', 2, 'Grape'],\n",
        "        ['Red', 1, 'Grape'],\n",
        "        ['Yellow', 3, 'Lemon'],\n",
        "    ]\n",
        "    for row in testing_data:\n",
        "        print(\"Actual: %s. Predicted: %s\" % (row[-1], print_leaf(classify(row, my_tree))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM58iIUjl-Up",
        "outputId": "ca9cabd9-9442-47fb-a7f4-76d893033128"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is diameter >= 3?\n",
            "---> True\n",
            " Is color == Yellow?\n",
            " ---> True\n",
            "  Predict {'Mango': 1, 'Lemon': 1}\n",
            " --> False\n",
            "  Predict {'Mango': 1}\n",
            "--> False\n",
            " Predict {'Grape': 2}\n",
            "Actual: Mango. Predicted: {'Mango': '100%'}\n",
            "Actual: Mango. Predicted: {'Mango': '50%', 'Lemon': '50%'}\n",
            "Actual: Grape. Predicted: {'Grape': '100%'}\n",
            "Actual: Grape. Predicted: {'Grape': '100%'}\n",
            "Actual: Lemon. Predicted: {'Mango': '50%', 'Lemon': '50%'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        " my_tree = build_tree(traning_data)\n",
        "    print_tree(my_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "RfLA9EJRzGOD",
        "outputId": "679bb66f-1f08-4628-c754-9bd5a8bf75f8"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-114-d206b63d9a91>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print_tree(my_tree)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    }
  ]
}